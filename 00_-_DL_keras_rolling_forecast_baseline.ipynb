{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-18T11:36:30.836664Z",
     "start_time": "2017-11-18T11:36:28.673750Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "%matplotlib inline\n",
    "\n",
    "# Display only top 5 and bottom 5 rows\n",
    "pd.set_option('display.max_rows', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-18T11:36:30.841457Z",
     "start_time": "2017-11-18T11:36:30.838244Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "# Note: CuDNN is usually non-deterministic\n",
    "# (can't determine which of the ~3000 threads finish earlier)\n",
    "# And floating points reduction is not perfectly associative due to ULP rounding\n",
    "import numpy as np\n",
    "np.random.seed(1337)\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-18T11:36:30.896079Z",
     "start_time": "2017-11-18T11:36:30.842623Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateTime</th>\n",
       "      <th>Junction</th>\n",
       "      <th>Vehicles</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-11-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>20151101001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-11-01 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>20151101011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-11-01 02:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>20151101021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-11-01 03:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>20151101031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-11-01 04:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>20151101041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48115</th>\n",
       "      <td>2017-06-30 19:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>20170630194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48116</th>\n",
       "      <td>2017-06-30 20:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>20170630204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48117</th>\n",
       "      <td>2017-06-30 21:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>20170630214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48118</th>\n",
       "      <td>2017-06-30 22:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>20170630224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48119</th>\n",
       "      <td>2017-06-30 23:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>20170630234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48120 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 DateTime  Junction  Vehicles           ID\n",
       "0     2015-11-01 00:00:00         1        15  20151101001\n",
       "1     2015-11-01 01:00:00         1        13  20151101011\n",
       "2     2015-11-01 02:00:00         1        10  20151101021\n",
       "3     2015-11-01 03:00:00         1         7  20151101031\n",
       "4     2015-11-01 04:00:00         1         9  20151101041\n",
       "...                   ...       ...       ...          ...\n",
       "48115 2017-06-30 19:00:00         4        11  20170630194\n",
       "48116 2017-06-30 20:00:00         4        30  20170630204\n",
       "48117 2017-06-30 21:00:00         4        16  20170630214\n",
       "48118 2017-06-30 22:00:00         4        22  20170630224\n",
       "48119 2017-06-30 23:00:00         4        12  20170630234\n",
       "\n",
       "[48120 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('./data/train_aWnotuB.csv', parse_dates=[0], infer_datetime_format=True)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-18T11:36:30.917275Z",
     "start_time": "2017-11-18T11:36:30.897359Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Junction</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DateTime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-11-01 00:00:00</th>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-11-01 01:00:00</th>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-11-01 02:00:00</th>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-11-01 03:00:00</th>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-11-01 04:00:00</th>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-30 19:00:00</th>\n",
       "      <td>105.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-30 20:00:00</th>\n",
       "      <td>96.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-30 21:00:00</th>\n",
       "      <td>90.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-30 22:00:00</th>\n",
       "      <td>84.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-30 23:00:00</th>\n",
       "      <td>78.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14592 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Junction                 1     2     3     4\n",
       "DateTime                                    \n",
       "2015-11-01 00:00:00   15.0   6.0   9.0   NaN\n",
       "2015-11-01 01:00:00   13.0   6.0   7.0   NaN\n",
       "2015-11-01 02:00:00   10.0   5.0   5.0   NaN\n",
       "2015-11-01 03:00:00    7.0   6.0   1.0   NaN\n",
       "2015-11-01 04:00:00    9.0   7.0   2.0   NaN\n",
       "...                    ...   ...   ...   ...\n",
       "2017-06-30 19:00:00  105.0  34.0  33.0  11.0\n",
       "2017-06-30 20:00:00   96.0  35.0  31.0  30.0\n",
       "2017-06-30 21:00:00   90.0  31.0  28.0  16.0\n",
       "2017-06-30 22:00:00   84.0  29.0  26.0  22.0\n",
       "2017-06-30 23:00:00   78.0  27.0  39.0  12.0\n",
       "\n",
       "[14592 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = df_train.pivot(index='DateTime',columns='Junction', values='Vehicles')\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-18T09:50:40.101929Z",
     "start_time": "2017-11-18T09:50:40.100033Z"
    }
   },
   "source": [
    "### Remove Nan (0 vehicle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-18T11:36:30.920713Z",
     "start_time": "2017-11-18T11:36:30.918595Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate rolling forecast features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-18T11:36:30.925604Z",
     "start_time": "2017-11-18T11:36:30.921695Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_forecast_per_junction = 24 * (31 + 31 + 30 + 31) # Days in jul + aug + sep + oct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-18T11:36:30.931175Z",
     "start_time": "2017-11-18T11:36:30.927010Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2952"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_forecast_per_junction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-18T11:36:30.936390Z",
     "start_time": "2017-11-18T11:36:30.932458Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11808"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_forecast_per_junction * 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That will certainly not fit in the GPU VRAM --> We will get inspiration from seq2seq models and do a sliding window of time that matches a week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-18T11:36:30.941472Z",
     "start_time": "2017-11-18T11:36:30.937736Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_feats = 4\n",
    "seq_len = 24 * 7 * 2 # Sequence of one week of traffic: 168\n",
    "num_outputs = 4\n",
    "num_hidden = 80 # Keep 80 * 2 weeks of hidden state\n",
    "bs = 512\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We originally had 14592 rows, we will generate sequences of predictions from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-18T11:36:30.954803Z",
     "start_time": "2017-11-18T11:36:30.942996Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_input_seqs(data, seq_len, train_split=0.9):\n",
    "    seq_len = seq_len + 1\n",
    "    result = []\n",
    "    for index in range(len(data) - seq_len):\n",
    "        result.append(data[index: index + seq_len, :])\n",
    "    result = np.array(result) # shape (14423, 168, 4)\n",
    "    train_ind = round(train_split * result.shape[0])\n",
    "    train = result[:int(train_ind), :, :]\n",
    "    x_train = train[:, :-1, :]\n",
    "    y_train = train[:, -1, :]\n",
    "    x_test = result[int(train_ind):, :-1, :]\n",
    "    y_test = result[int(train_ind):, -1, :]\n",
    "\n",
    "    return [x_train, y_train, x_test, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-18T11:36:31.020603Z",
     "start_time": "2017-11-18T11:36:30.956083Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = make_input_seqs(train.values, seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-18T11:36:31.024425Z",
     "start_time": "2017-11-18T11:36:31.021789Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-18T11:36:31.035073Z",
     "start_time": "2017-11-18T11:36:31.025539Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Net(num_feats, seq_len, num_hidden, num_outputs):\n",
    "    model = Sequential()\n",
    "\n",
    "    # Encoder RNN\n",
    "    model.add(LSTM(\n",
    "        input_shape=(seq_len,num_feats),\n",
    "        return_sequences=True, units=seq_len))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    # Deoder RNN\n",
    "    model.add(LSTM(\n",
    "        num_hidden,\n",
    "        return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(num_outputs))\n",
    "    model.add(Activation(\"linear\"))\n",
    "\n",
    "    model.compile(loss= root_mean_squared_error, optimizer=\"rmsprop\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-18T11:36:31.567299Z",
     "start_time": "2017-11-18T11:36:31.036124Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Net(num_feats, seq_len, num_hidden, num_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-18T11:36:31.571814Z",
     "start_time": "2017-11-18T11:36:31.568337Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 336, 336)          458304    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 336, 336)          0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 80)                133440    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 324       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 592,068\n",
      "Trainable params: 592,068\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-18T11:26:59.040374Z",
     "start_time": "2017-11-18T11:26:59.038563Z"
    }
   },
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-18T11:36:31.577086Z",
     "start_time": "2017-11-18T11:36:31.572827Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import History, ModelCheckpoint, CSVLogger, EarlyStopping\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-11-18T11:36:28.703Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "history = History()\n",
    "checkpointer = ModelCheckpoint(filepath=\"checkpoints/\" + time.strftime(\"%Y-%m-%d_%H%M-\")+\"seq2seq.hdf5\",\n",
    "                               verbose=1, save_best_only=False)\n",
    "csv_logger = CSVLogger(\"checkpoints/\" + time.strftime(\"%Y-%m-%d_%H%M-\")+'training.log')\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-11-18T11:36:28.713Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12188 samples, validate on 642 samples\n",
      "Epoch 1/50\n",
      "\n",
      "  512/12188 [>.............................] - ETA: 49s - loss: 22.9703\n",
      " 1024/12188 [=>............................] - ETA: 32s - loss: 22.0077\n",
      " 1536/12188 [==>...........................] - ETA: 26s - loss: 21.4185\n",
      " 2048/12188 [====>.........................] - ETA: 22s - loss: 20.8120\n",
      " 2560/12188 [=====>........................] - ETA: 20s - loss: 20.4738\n",
      " 3072/12188 [======>.......................] - ETA: 18s - loss: 20.0990\n",
      " 3584/12188 [=======>......................] - ETA: 16s - loss: 19.6547\n",
      " 4096/12188 [=========>....................] - ETA: 15s - loss: 19.3011\n",
      " 4608/12188 [==========>...................] - ETA: 14s - loss: 19.0591\n",
      " 5120/12188 [===========>..................] - ETA: 12s - loss: 18.8271\n",
      " 5632/12188 [============>.................] - ETA: 11s - loss: 18.6750\n",
      " 6144/12188 [==============>...............] - ETA: 10s - loss: 18.4944\n",
      " 6656/12188 [===============>..............] - ETA: 9s - loss: 18.3431 \n",
      " 7168/12188 [================>.............] - ETA: 8s - loss: 18.2608\n",
      " 7680/12188 [=================>............] - ETA: 8s - loss: 18.1217\n",
      " 8192/12188 [===================>..........] - ETA: 7s - loss: 18.0089\n",
      " 8704/12188 [====================>.........] - ETA: 6s - loss: 17.9067\n",
      " 9216/12188 [=====================>........] - ETA: 5s - loss: 17.8744\n",
      " 9728/12188 [======================>.......] - ETA: 4s - loss: 17.8350\n",
      "10240/12188 [========================>.....] - ETA: 3s - loss: 17.7628\n",
      "10752/12188 [=========================>....] - ETA: 2s - loss: 17.7422\n",
      "11264/12188 [==========================>...] - ETA: 1s - loss: 17.6792\n",
      "11776/12188 [===========================>..] - ETA: 1s - loss: 17.6295Epoch 00001: saving model to checkpoints/2017-11-18_1136-seq2seq.hdf5\n",
      "\n",
      "12188/12188 [==============================] - ETA: 0s - loss: 17.5855 - val_loss: 27.9264\n",
      "Epoch 2/50\n",
      "\n",
      "  512/12188 [>.............................] - ETA: 17s - loss: 16.6682\n",
      " 1024/12188 [=>............................] - ETA: 17s - loss: 16.3001\n",
      " 1536/12188 [==>...........................] - ETA: 16s - loss: 16.0900\n",
      " 2048/12188 [====>.........................] - ETA: 15s - loss: 16.0573\n",
      " 2560/12188 [=====>........................] - ETA: 14s - loss: 16.0159\n",
      " 3072/12188 [======>.......................] - ETA: 14s - loss: 16.0221\n",
      " 3584/12188 [=======>......................] - ETA: 13s - loss: 16.0514\n",
      " 4096/12188 [=========>....................] - ETA: 12s - loss: 15.9640\n",
      " 4608/12188 [==========>...................] - ETA: 11s - loss: 15.9814\n",
      " 5120/12188 [===========>..................] - ETA: 11s - loss: 15.9105\n",
      " 5632/12188 [============>.................] - ETA: 10s - loss: 15.7978\n",
      " 6144/12188 [==============>...............] - ETA: 9s - loss: 15.7284 \n",
      " 6656/12188 [===============>..............] - ETA: 8s - loss: 15.7410\n",
      " 7168/12188 [================>.............] - ETA: 8s - loss: 15.7614\n",
      " 7680/12188 [=================>............] - ETA: 7s - loss: 15.7432\n",
      " 8192/12188 [===================>..........] - ETA: 6s - loss: 15.7226\n",
      " 8704/12188 [====================>.........] - ETA: 5s - loss: 15.6872\n",
      " 9216/12188 [=====================>........] - ETA: 4s - loss: 15.6876\n",
      " 9728/12188 [======================>.......] - ETA: 4s - loss: 15.6718\n",
      "10240/12188 [========================>.....] - ETA: 3s - loss: 15.6447\n",
      "10752/12188 [=========================>....] - ETA: 2s - loss: 15.6003\n",
      "11264/12188 [==========================>...] - ETA: 1s - loss: 15.5723\n",
      "11776/12188 [===========================>..] - ETA: 1s - loss: 15.5601Epoch 00002: saving model to checkpoints/2017-11-18_1136-seq2seq.hdf5\n",
      "\n",
      "12188/12188 [==============================] - ETA: 0s - loss: 15.5324 - val_loss: 26.5664\n",
      "Epoch 3/50\n",
      "\n",
      "  512/12188 [>.............................] - ETA: 17s - loss: 15.1712\n",
      " 1024/12188 [=>............................] - ETA: 17s - loss: 14.8434\n",
      " 1536/12188 [==>...........................] - ETA: 16s - loss: 14.8880\n",
      " 2048/12188 [====>.........................] - ETA: 15s - loss: 14.8634\n",
      " 2560/12188 [=====>........................] - ETA: 14s - loss: 14.8862\n",
      " 3072/12188 [======>.......................] - ETA: 14s - loss: 14.8721\n",
      " 3584/12188 [=======>......................] - ETA: 13s - loss: 14.8829\n",
      " 4096/12188 [=========>....................] - ETA: 12s - loss: 14.8997\n",
      " 4608/12188 [==========>...................] - ETA: 11s - loss: 14.8558\n",
      " 5120/12188 [===========>..................] - ETA: 11s - loss: 14.8059\n",
      " 5632/12188 [============>.................] - ETA: 10s - loss: 14.7897\n",
      " 6144/12188 [==============>...............] - ETA: 9s - loss: 14.7676 \n",
      " 6656/12188 [===============>..............] - ETA: 8s - loss: 14.7622\n",
      " 7168/12188 [================>.............] - ETA: 8s - loss: 14.7347\n",
      " 7680/12188 [=================>............] - ETA: 7s - loss: 14.7534\n",
      " 8192/12188 [===================>..........] - ETA: 6s - loss: 14.7223\n",
      " 8704/12188 [====================>.........] - ETA: 5s - loss: 14.6923\n",
      " 9216/12188 [=====================>........] - ETA: 4s - loss: 14.6525\n",
      " 9728/12188 [======================>.......] - ETA: 4s - loss: 14.6164\n",
      "10240/12188 [========================>.....] - ETA: 3s - loss: 14.6159\n",
      "10752/12188 [=========================>....] - ETA: 2s - loss: 14.6301\n",
      "11264/12188 [==========================>...] - ETA: 1s - loss: 14.5688\n",
      "11776/12188 [===========================>..] - ETA: 1s - loss: 14.5285Epoch 00003: saving model to checkpoints/2017-11-18_1136-seq2seq.hdf5\n",
      "\n",
      "12188/12188 [==============================] - ETA: 0s - loss: 14.4967 - val_loss: 25.5097\n",
      "Epoch 4/50\n",
      "\n",
      "  512/12188 [>.............................] - ETA: 18s - loss: 14.0554\n",
      " 1024/12188 [=>............................] - ETA: 17s - loss: 14.1079\n",
      " 1536/12188 [==>...........................] - ETA: 16s - loss: 14.2043\n",
      " 2048/12188 [====>.........................] - ETA: 15s - loss: 14.0690\n",
      " 2560/12188 [=====>........................] - ETA: 14s - loss: 14.0727\n",
      " 3072/12188 [======>.......................] - ETA: 14s - loss: 13.9863\n",
      " 3584/12188 [=======>......................] - ETA: 13s - loss: 13.8986\n",
      " 4096/12188 [=========>....................] - ETA: 12s - loss: 13.9243\n",
      " 4608/12188 [==========>...................] - ETA: 11s - loss: 13.8972\n",
      " 5120/12188 [===========>..................] - ETA: 11s - loss: 13.8636\n",
      " 5632/12188 [============>.................] - ETA: 10s - loss: 13.8252\n",
      " 6144/12188 [==============>...............] - ETA: 9s - loss: 13.8817 \n",
      " 6656/12188 [===============>..............] - ETA: 8s - loss: 13.8372\n",
      " 7168/12188 [================>.............] - ETA: 8s - loss: 13.8249\n",
      " 7680/12188 [=================>............] - ETA: 7s - loss: 13.8256\n",
      " 8192/12188 [===================>..........] - ETA: 6s - loss: 13.8081\n",
      " 8704/12188 [====================>.........] - ETA: 5s - loss: 13.7667\n",
      " 9216/12188 [=====================>........] - ETA: 4s - loss: 13.7903\n",
      " 9728/12188 [======================>.......] - ETA: 4s - loss: 13.7973\n",
      "10240/12188 [========================>.....] - ETA: 3s - loss: 13.7538\n",
      "10752/12188 [=========================>....] - ETA: 2s - loss: 13.7263\n",
      "11264/12188 [==========================>...] - ETA: 1s - loss: 13.7220\n",
      "11776/12188 [===========================>..] - ETA: 1s - loss: 13.6759Epoch 00004: saving model to checkpoints/2017-11-18_1136-seq2seq.hdf5\n",
      "\n",
      "12188/12188 [==============================] - ETA: 0s - loss: 13.6747 - val_loss: 24.1369\n",
      "Epoch 5/50\n",
      "\n",
      "  512/12188 [>.............................] - ETA: 17s - loss: 13.8928\n",
      " 1024/12188 [=>............................] - ETA: 17s - loss: 13.6182\n",
      " 1536/12188 [==>...........................] - ETA: 16s - loss: 13.6728\n",
      " 2048/12188 [====>.........................] - ETA: 15s - loss: 13.6239\n",
      " 2560/12188 [=====>........................] - ETA: 14s - loss: 13.4409\n",
      " 3072/12188 [======>.......................] - ETA: 14s - loss: 13.3677\n",
      " 3584/12188 [=======>......................] - ETA: 13s - loss: 13.3197\n",
      " 4096/12188 [=========>....................] - ETA: 12s - loss: 13.2136\n",
      " 4608/12188 [==========>...................] - ETA: 11s - loss: 13.1193\n",
      " 5120/12188 [===========>..................] - ETA: 11s - loss: 13.0841\n",
      " 5632/12188 [============>.................] - ETA: 10s - loss: 13.0250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 6144/12188 [==============>...............] - ETA: 9s - loss: 12.9724 \n",
      " 6656/12188 [===============>..............] - ETA: 8s - loss: 12.9186\n",
      " 7168/12188 [================>.............] - ETA: 8s - loss: 12.8992\n",
      " 7680/12188 [=================>............] - ETA: 7s - loss: 12.8906\n",
      " 8192/12188 [===================>..........] - ETA: 6s - loss: 12.8235\n",
      " 8704/12188 [====================>.........] - ETA: 5s - loss: 12.8913\n",
      " 9216/12188 [=====================>........] - ETA: 4s - loss: 12.8773\n",
      " 9728/12188 [======================>.......] - ETA: 4s - loss: 12.8622\n",
      "10240/12188 [========================>.....] - ETA: 3s - loss: 12.8623\n",
      "10752/12188 [=========================>....] - ETA: 2s - loss: 12.8430\n",
      "11264/12188 [==========================>...] - ETA: 1s - loss: 12.8238\n",
      "11776/12188 [===========================>..] - ETA: 1s - loss: 12.7999Epoch 00005: saving model to checkpoints/2017-11-18_1136-seq2seq.hdf5\n",
      "\n",
      "12188/12188 [==============================] - ETA: 0s - loss: 12.8087 - val_loss: 23.0287\n",
      "Epoch 6/50\n",
      "\n",
      "  512/12188 [>.............................] - ETA: 17s - loss: 12.8965\n",
      " 1024/12188 [=>............................] - ETA: 17s - loss: 12.3840\n",
      " 1536/12188 [==>...........................] - ETA: 16s - loss: 12.2944\n",
      " 2048/12188 [====>.........................] - ETA: 15s - loss: 12.3030\n",
      " 2560/12188 [=====>........................] - ETA: 14s - loss: 12.3461\n",
      " 3072/12188 [======>.......................] - ETA: 14s - loss: 12.4443\n",
      " 3584/12188 [=======>......................] - ETA: 13s - loss: 12.3453\n",
      " 4096/12188 [=========>....................] - ETA: 12s - loss: 12.2873\n",
      " 4608/12188 [==========>...................] - ETA: 11s - loss: 12.2553\n",
      " 5120/12188 [===========>..................] - ETA: 11s - loss: 12.2251\n",
      " 5632/12188 [============>.................] - ETA: 10s - loss: 12.2457\n",
      " 6144/12188 [==============>...............] - ETA: 9s - loss: 12.2549 \n",
      " 6656/12188 [===============>..............] - ETA: 8s - loss: 12.2410\n",
      " 7168/12188 [================>.............] - ETA: 8s - loss: 12.2507\n",
      " 7680/12188 [=================>............] - ETA: 7s - loss: 12.2088\n",
      " 8192/12188 [===================>..........] - ETA: 6s - loss: 12.1926\n",
      " 8704/12188 [====================>.........] - ETA: 5s - loss: 12.1886\n",
      " 9216/12188 [=====================>........] - ETA: 4s - loss: 12.2044\n",
      " 9728/12188 [======================>.......] - ETA: 4s - loss: 12.1480\n",
      "10240/12188 [========================>.....] - ETA: 3s - loss: 12.1036\n",
      "10752/12188 [=========================>....] - ETA: 2s - loss: 12.0827\n",
      "11264/12188 [==========================>...] - ETA: 1s - loss: 12.0566\n",
      "11776/12188 [===========================>..] - ETA: 1s - loss: 12.0529Epoch 00006: saving model to checkpoints/2017-11-18_1136-seq2seq.hdf5\n",
      "\n",
      "12188/12188 [==============================] - ETA: 0s - loss: 12.0347 - val_loss: 22.0064\n",
      "Epoch 7/50\n",
      "\n",
      "  512/12188 [>.............................] - ETA: 17s - loss: 11.5539\n",
      " 1024/12188 [=>............................] - ETA: 17s - loss: 11.5493\n",
      " 1536/12188 [==>...........................] - ETA: 16s - loss: 11.4262\n",
      " 2048/12188 [====>.........................] - ETA: 15s - loss: 11.5573\n",
      " 2560/12188 [=====>........................] - ETA: 14s - loss: 11.6422\n",
      " 3072/12188 [======>.......................] - ETA: 14s - loss: 11.7010\n",
      " 3584/12188 [=======>......................] - ETA: 13s - loss: 11.7062\n",
      " 4096/12188 [=========>....................] - ETA: 12s - loss: 11.6679\n",
      " 4608/12188 [==========>...................] - ETA: 11s - loss: 11.5831\n",
      " 5120/12188 [===========>..................] - ETA: 11s - loss: 11.5235\n",
      " 5632/12188 [============>.................] - ETA: 10s - loss: 11.5329\n",
      " 6144/12188 [==============>...............] - ETA: 9s - loss: 11.5530 \n",
      " 6656/12188 [===============>..............] - ETA: 8s - loss: 11.4974\n",
      " 7168/12188 [================>.............] - ETA: 8s - loss: 11.4935\n",
      " 7680/12188 [=================>............] - ETA: 7s - loss: 11.4683\n",
      " 8192/12188 [===================>..........] - ETA: 6s - loss: 11.3969\n",
      " 8704/12188 [====================>.........] - ETA: 5s - loss: 11.3876\n",
      " 9216/12188 [=====================>........] - ETA: 4s - loss: 11.3898\n",
      " 9728/12188 [======================>.......] - ETA: 4s - loss: 11.3718\n",
      "10240/12188 [========================>.....] - ETA: 3s - loss: 11.3415\n",
      "10752/12188 [=========================>....] - ETA: 2s - loss: 11.3119\n",
      "11264/12188 [==========================>...] - ETA: 1s - loss: 11.3312\n",
      "11776/12188 [===========================>..] - ETA: 1s - loss: 11.3101Epoch 00007: saving model to checkpoints/2017-11-18_1136-seq2seq.hdf5\n",
      "\n",
      "12188/12188 [==============================] - ETA: 0s - loss: 11.3182 - val_loss: 21.0771\n",
      "Epoch 8/50\n",
      "\n",
      "  512/12188 [>.............................] - ETA: 18s - loss: 10.5439\n",
      " 1024/12188 [=>............................] - ETA: 17s - loss: 10.7811\n",
      " 1536/12188 [==>...........................] - ETA: 16s - loss: 10.7644\n",
      " 2048/12188 [====>.........................] - ETA: 15s - loss: 10.8912\n",
      " 2560/12188 [=====>........................] - ETA: 15s - loss: 10.8033\n",
      " 3072/12188 [======>.......................] - ETA: 14s - loss: 10.8081\n",
      " 3584/12188 [=======>......................] - ETA: 13s - loss: 10.8163\n",
      " 4096/12188 [=========>....................] - ETA: 12s - loss: 10.7343\n",
      " 4608/12188 [==========>...................] - ETA: 11s - loss: 10.7039\n",
      " 5120/12188 [===========>..................] - ETA: 11s - loss: 10.7449\n",
      " 5632/12188 [============>.................] - ETA: 10s - loss: 10.7862\n",
      " 6144/12188 [==============>...............] - ETA: 9s - loss: 10.7942 \n",
      " 6656/12188 [===============>..............] - ETA: 8s - loss: 10.7810\n",
      " 7168/12188 [================>.............] - ETA: 8s - loss: 10.8232\n",
      " 7680/12188 [=================>............] - ETA: 7s - loss: 10.7556\n",
      " 8192/12188 [===================>..........] - ETA: 6s - loss: 10.7019\n",
      " 8704/12188 [====================>.........] - ETA: 5s - loss: 10.7097\n",
      " 9216/12188 [=====================>........] - ETA: 4s - loss: 10.6897\n",
      " 9728/12188 [======================>.......] - ETA: 4s - loss: 10.6870\n",
      "10240/12188 [========================>.....] - ETA: 3s - loss: 10.7021\n",
      "10752/12188 [=========================>....] - ETA: 2s - loss: 10.6859\n",
      "11264/12188 [==========================>...] - ETA: 1s - loss: 10.6670\n",
      "11776/12188 [===========================>..] - ETA: 1s - loss: 10.6729Epoch 00008: saving model to checkpoints/2017-11-18_1136-seq2seq.hdf5\n",
      "\n",
      "12188/12188 [==============================] - ETA: 0s - loss: 10.6547 - val_loss: 20.1866\n",
      "Epoch 9/50\n",
      "\n",
      "  512/12188 [>.............................] - ETA: 17s - loss: 10.6019\n",
      " 1024/12188 [=>............................] - ETA: 17s - loss: 10.2087\n",
      " 1536/12188 [==>...........................] - ETA: 16s - loss: 10.1162\n",
      " 2048/12188 [====>.........................] - ETA: 15s - loss: 10.0228\n",
      " 2560/12188 [=====>........................] - ETA: 14s - loss: 10.1143\n",
      " 3072/12188 [======>.......................] - ETA: 14s - loss: 10.2302\n",
      " 3584/12188 [=======>......................] - ETA: 13s - loss: 10.2288\n",
      " 4096/12188 [=========>....................] - ETA: 12s - loss: 10.1964\n",
      " 4608/12188 [==========>...................] - ETA: 11s - loss: 10.2249\n",
      " 5120/12188 [===========>..................] - ETA: 11s - loss: 10.1578\n",
      " 5632/12188 [============>.................] - ETA: 10s - loss: 10.1611\n",
      " 6144/12188 [==============>...............] - ETA: 9s - loss: 10.1465 \n",
      " 6656/12188 [===============>..............] - ETA: 8s - loss: 10.1632\n",
      " 7168/12188 [================>.............] - ETA: 8s - loss: 10.1281\n",
      " 7680/12188 [=================>............] - ETA: 7s - loss: 10.1317\n",
      " 8192/12188 [===================>..........] - ETA: 6s - loss: 10.1425\n",
      " 8704/12188 [====================>.........] - ETA: 5s - loss: 10.1441\n",
      " 9216/12188 [=====================>........] - ETA: 4s - loss: 10.1242\n",
      " 9728/12188 [======================>.......] - ETA: 4s - loss: 10.1133\n",
      "10240/12188 [========================>.....] - ETA: 3s - loss: 10.1102\n",
      "10752/12188 [=========================>....] - ETA: 2s - loss: 10.0756\n",
      "11264/12188 [==========================>...] - ETA: 1s - loss: 10.0693\n",
      "11776/12188 [===========================>..] - ETA: 1s - loss: 10.0574Epoch 00009: saving model to checkpoints/2017-11-18_1136-seq2seq.hdf5\n",
      "\n",
      "12188/12188 [==============================] - ETA: 0s - loss: 10.0567 - val_loss: 19.2723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50\n",
      "\n",
      "  512/12188 [>.............................] - ETA: 17s - loss: 9.8119\n",
      " 1024/12188 [=>............................] - ETA: 17s - loss: 9.7613\n",
      " 1536/12188 [==>...........................] - ETA: 16s - loss: 9.6421\n",
      " 2048/12188 [====>.........................] - ETA: 15s - loss: 9.6330\n",
      " 2560/12188 [=====>........................] - ETA: 14s - loss: 9.7066\n",
      " 3072/12188 [======>.......................] - ETA: 14s - loss: 9.7901\n",
      " 3584/12188 [=======>......................] - ETA: 13s - loss: 9.7772\n",
      " 4096/12188 [=========>....................] - ETA: 12s - loss: 9.7404\n",
      " 4608/12188 [==========>...................] - ETA: 11s - loss: 9.7738\n",
      " 5120/12188 [===========>..................] - ETA: 11s - loss: 9.7478\n",
      " 5632/12188 [============>.................] - ETA: 10s - loss: 9.6729\n",
      " 6144/12188 [==============>...............] - ETA: 9s - loss: 9.6771 \n",
      " 6656/12188 [===============>..............] - ETA: 8s - loss: 9.6116\n",
      " 7168/12188 [================>.............] - ETA: 8s - loss: 9.5913\n",
      " 7680/12188 [=================>............] - ETA: 7s - loss: 9.5792\n",
      " 8192/12188 [===================>..........] - ETA: 6s - loss: 9.5558\n",
      " 8704/12188 [====================>.........] - ETA: 5s - loss: 9.5210\n",
      " 9216/12188 [=====================>........] - ETA: 4s - loss: 9.4966\n",
      " 9728/12188 [======================>.......] - ETA: 4s - loss: 9.4902\n",
      "10240/12188 [========================>.....] - ETA: 3s - loss: 9.4768\n",
      "10752/12188 [=========================>....] - ETA: 2s - loss: 9.4960\n",
      "11264/12188 [==========================>...] - ETA: 1s - loss: 9.4733\n",
      "11776/12188 [===========================>..] - ETA: 1s - loss: 9.4934Epoch 00010: saving model to checkpoints/2017-11-18_1136-seq2seq.hdf5\n",
      "\n",
      "12188/12188 [==============================] - ETA: 0s - loss: 9.4870 - val_loss: 18.4566\n",
      "Epoch 11/50\n",
      "\n",
      "  512/12188 [>.............................] - ETA: 18s - loss: 9.1268\n",
      " 1024/12188 [=>............................] - ETA: 17s - loss: 9.1833\n",
      " 1536/12188 [==>...........................] - ETA: 16s - loss: 9.0727\n",
      " 2048/12188 [====>.........................] - ETA: 15s - loss: 9.0620\n",
      " 2560/12188 [=====>........................] - ETA: 14s - loss: 9.1501\n",
      " 3072/12188 [======>.......................] - ETA: 14s - loss: 9.1203\n",
      " 3584/12188 [=======>......................] - ETA: 13s - loss: 9.1123\n",
      " 4096/12188 [=========>....................] - ETA: 12s - loss: 9.1460\n",
      " 4608/12188 [==========>...................] - ETA: 11s - loss: 9.1046\n",
      " 5120/12188 [===========>..................] - ETA: 11s - loss: 9.0755\n",
      " 5632/12188 [============>.................] - ETA: 10s - loss: 9.0677\n",
      " 6144/12188 [==============>...............] - ETA: 9s - loss: 9.0461 \n",
      " 6656/12188 [===============>..............] - ETA: 8s - loss: 9.0379\n",
      " 7168/12188 [================>.............] - ETA: 8s - loss: 9.0596\n",
      " 7680/12188 [=================>............] - ETA: 7s - loss: 9.0300\n",
      " 8192/12188 [===================>..........] - ETA: 6s - loss: 9.0252\n",
      " 8704/12188 [====================>.........] - ETA: 5s - loss: 8.9943\n",
      " 9216/12188 [=====================>........] - ETA: 4s - loss: 8.9966\n",
      " 9728/12188 [======================>.......] - ETA: 4s - loss: 9.0067\n",
      "10240/12188 [========================>.....] - ETA: 3s - loss: 8.9772\n",
      "10752/12188 [=========================>....] - ETA: 2s - loss: 8.9742\n",
      "11264/12188 [==========================>...] - ETA: 1s - loss: 8.9335\n",
      "11776/12188 [===========================>..] - ETA: 1s - loss: 8.9356Epoch 00011: saving model to checkpoints/2017-11-18_1136-seq2seq.hdf5\n",
      "\n",
      "12188/12188 [==============================] - ETA: 0s - loss: 8.9303 - val_loss: 17.6210\n",
      "Epoch 12/50\n",
      "\n",
      "  512/12188 [>.............................] - ETA: 18s - loss: 8.9127\n",
      " 1024/12188 [=>............................] - ETA: 17s - loss: 8.6634\n",
      " 1536/12188 [==>...........................] - ETA: 16s - loss: 8.7960\n",
      " 2048/12188 [====>.........................] - ETA: 15s - loss: 8.7381\n",
      " 2560/12188 [=====>........................] - ETA: 15s - loss: 8.5990\n",
      " 3072/12188 [======>.......................] - ETA: 14s - loss: 8.6047\n",
      " 3584/12188 [=======>......................] - ETA: 13s - loss: 8.6399\n",
      " 4096/12188 [=========>....................] - ETA: 12s - loss: 8.6295\n",
      " 4608/12188 [==========>...................] - ETA: 11s - loss: 8.5992\n",
      " 5120/12188 [===========>..................] - ETA: 11s - loss: 8.5762\n",
      " 5632/12188 [============>.................] - ETA: 10s - loss: 8.5855\n",
      " 6144/12188 [==============>...............] - ETA: 9s - loss: 8.5887 \n",
      " 6656/12188 [===============>..............] - ETA: 8s - loss: 8.5976\n",
      " 7168/12188 [================>.............] - ETA: 8s - loss: 8.5288\n",
      " 7680/12188 [=================>............] - ETA: 7s - loss: 8.5344\n",
      " 8192/12188 [===================>..........] - ETA: 6s - loss: 8.5354\n",
      " 8704/12188 [====================>.........] - ETA: 5s - loss: 8.5186\n",
      " 9216/12188 [=====================>........] - ETA: 4s - loss: 8.5350\n",
      " 9728/12188 [======================>.......] - ETA: 4s - loss: 8.5158\n",
      "10240/12188 [========================>.....] - ETA: 3s - loss: 8.4832\n",
      "10752/12188 [=========================>....] - ETA: 2s - loss: 8.4528\n",
      "11264/12188 [==========================>...] - ETA: 1s - loss: 8.4264\n",
      "11776/12188 [===========================>..] - ETA: 1s - loss: 8.4319Epoch 00012: saving model to checkpoints/2017-11-18_1136-seq2seq.hdf5\n",
      "\n",
      "12188/12188 [==============================] - ETA: 0s - loss: 8.4229 - val_loss: 16.8048\n",
      "Epoch 13/50\n",
      "\n",
      "  512/12188 [>.............................] - ETA: 18s - loss: 8.7428\n",
      " 1024/12188 [=>............................] - ETA: 17s - loss: 8.3699\n",
      " 1536/12188 [==>...........................] - ETA: 16s - loss: 8.6459\n",
      " 2048/12188 [====>.........................] - ETA: 15s - loss: 8.3554\n",
      " 2560/12188 [=====>........................] - ETA: 14s - loss: 8.3149\n",
      " 3072/12188 [======>.......................] - ETA: 14s - loss: 8.2755\n",
      " 3584/12188 [=======>......................] - ETA: 13s - loss: 8.2903\n",
      " 4096/12188 [=========>....................] - ETA: 12s - loss: 8.3136\n",
      " 4608/12188 [==========>...................] - ETA: 11s - loss: 8.3292\n",
      " 5120/12188 [===========>..................] - ETA: 11s - loss: 8.2758\n",
      " 5632/12188 [============>.................] - ETA: 10s - loss: 8.3266\n",
      " 6144/12188 [==============>...............] - ETA: 9s - loss: 8.3507 \n",
      " 6656/12188 [===============>..............] - ETA: 8s - loss: 8.3131\n",
      " 7168/12188 [================>.............] - ETA: 8s - loss: 8.2968\n",
      " 7680/12188 [=================>............] - ETA: 7s - loss: 8.2545\n",
      " 8192/12188 [===================>..........] - ETA: 6s - loss: 8.2057\n",
      " 8704/12188 [====================>.........] - ETA: 5s - loss: 8.1522\n",
      " 9216/12188 [=====================>........] - ETA: 4s - loss: 8.1481\n",
      " 9728/12188 [======================>.......] - ETA: 4s - loss: 8.1174\n",
      "10240/12188 [========================>.....] - ETA: 3s - loss: 8.1053\n",
      "10752/12188 [=========================>....] - ETA: 2s - loss: 8.0984\n",
      "11264/12188 [==========================>...] - ETA: 1s - loss: 8.0617\n",
      "11776/12188 [===========================>..] - ETA: 1s - loss: 8.0381Epoch 00013: saving model to checkpoints/2017-11-18_1136-seq2seq.hdf5\n",
      "\n",
      "12188/12188 [==============================] - ETA: 0s - loss: 8.0088 - val_loss: 16.0121\n",
      "Epoch 14/50\n",
      "\n",
      "  512/12188 [>.............................] - ETA: 18s - loss: 7.8804\n",
      " 1024/12188 [=>............................] - ETA: 17s - loss: 7.8967\n",
      " 1536/12188 [==>...........................] - ETA: 16s - loss: 7.7938\n",
      " 2048/12188 [====>.........................] - ETA: 15s - loss: 7.6052\n",
      " 2560/12188 [=====>........................] - ETA: 14s - loss: 7.5088\n",
      " 3072/12188 [======>.......................] - ETA: 14s - loss: 7.4714\n",
      " 3584/12188 [=======>......................] - ETA: 13s - loss: 7.5068\n",
      " 4096/12188 [=========>....................] - ETA: 12s - loss: 7.5513\n",
      " 4608/12188 [==========>...................] - ETA: 11s - loss: 7.6210\n",
      " 5120/12188 [===========>..................] - ETA: 11s - loss: 7.5932\n",
      " 5632/12188 [============>.................] - ETA: 10s - loss: 7.6053\n",
      " 6144/12188 [==============>...............] - ETA: 9s - loss: 7.5817 \n",
      " 6656/12188 [===============>..............] - ETA: 8s - loss: 7.6074\n",
      " 7168/12188 [================>.............] - ETA: 8s - loss: 7.6122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 7680/12188 [=================>............] - ETA: 7s - loss: 7.5807\n",
      " 8192/12188 [===================>..........] - ETA: 6s - loss: 7.5535\n",
      " 8704/12188 [====================>.........] - ETA: 5s - loss: 7.5347\n",
      " 9216/12188 [=====================>........] - ETA: 4s - loss: 7.5137\n",
      " 9728/12188 [======================>.......] - ETA: 4s - loss: 7.5051\n",
      "10240/12188 [========================>.....] - ETA: 3s - loss: 7.5209\n",
      "10752/12188 [=========================>....] - ETA: 2s - loss: 7.5315\n",
      "11264/12188 [==========================>...] - ETA: 1s - loss: 7.5346\n",
      "11776/12188 [===========================>..] - ETA: 1s - loss: 7.5444Epoch 00014: saving model to checkpoints/2017-11-18_1136-seq2seq.hdf5\n",
      "\n",
      "12188/12188 [==============================] - ETA: 0s - loss: 7.5233 - val_loss: 15.2803\n",
      "Epoch 15/50\n",
      "\n",
      "  512/12188 [>.............................] - ETA: 18s - loss: 6.9130\n",
      " 1024/12188 [=>............................] - ETA: 17s - loss: 6.9279\n",
      " 1536/12188 [==>...........................] - ETA: 16s - loss: 6.9918\n",
      " 2048/12188 [====>.........................] - ETA: 15s - loss: 7.1206\n",
      " 2560/12188 [=====>........................] - ETA: 14s - loss: 7.0730\n",
      " 3072/12188 [======>.......................] - ETA: 14s - loss: 7.1632\n",
      " 3584/12188 [=======>......................] - ETA: 13s - loss: 7.2300\n",
      " 4096/12188 [=========>....................] - ETA: 12s - loss: 7.2735\n",
      " 4608/12188 [==========>...................] - ETA: 11s - loss: 7.2391\n",
      " 5120/12188 [===========>..................] - ETA: 11s - loss: 7.2712\n",
      " 5632/12188 [============>.................] - ETA: 10s - loss: 7.2870\n",
      " 6144/12188 [==============>...............] - ETA: 9s - loss: 7.2992 \n",
      " 6656/12188 [===============>..............] - ETA: 8s - loss: 7.2839\n",
      " 7168/12188 [================>.............] - ETA: 8s - loss: 7.2553\n",
      " 7680/12188 [=================>............] - ETA: 7s - loss: 7.2372\n",
      " 8192/12188 [===================>..........] - ETA: 6s - loss: 7.2096\n",
      " 8704/12188 [====================>.........] - ETA: 5s - loss: 7.1931\n",
      " 9216/12188 [=====================>........] - ETA: 4s - loss: 7.1634\n",
      " 9728/12188 [======================>.......] - ETA: 4s - loss: 7.1741\n",
      "10240/12188 [========================>.....] - ETA: 3s - loss: 7.1792\n",
      "10752/12188 [=========================>....] - ETA: 2s - loss: 7.1812\n",
      "11264/12188 [==========================>...] - ETA: 1s - loss: 7.1733\n",
      "11776/12188 [===========================>..] - ETA: 1s - loss: 7.1654Epoch 00015: saving model to checkpoints/2017-11-18_1136-seq2seq.hdf5\n",
      "\n",
      "12188/12188 [==============================] - ETA: 0s - loss: 7.1368 - val_loss: 14.5362\n",
      "Epoch 16/50\n",
      "\n",
      "  512/12188 [>.............................] - ETA: 17s - loss: 7.3036\n",
      " 1024/12188 [=>............................] - ETA: 17s - loss: 7.2585\n",
      " 1536/12188 [==>...........................] - ETA: 16s - loss: 7.0987\n",
      " 2048/12188 [====>.........................] - ETA: 15s - loss: 7.2012\n",
      " 2560/12188 [=====>........................] - ETA: 14s - loss: 7.1213\n",
      " 3072/12188 [======>.......................] - ETA: 14s - loss: 6.9947\n",
      " 3584/12188 [=======>......................] - ETA: 13s - loss: 6.9715\n",
      " 4096/12188 [=========>....................] - ETA: 12s - loss: 6.9486\n",
      " 4608/12188 [==========>...................] - ETA: 11s - loss: 6.9102\n",
      " 5120/12188 [===========>..................] - ETA: 11s - loss: 6.8772\n",
      " 5632/12188 [============>.................] - ETA: 10s - loss: 6.8563\n",
      " 6144/12188 [==============>...............] - ETA: 9s - loss: 6.9260 \n",
      " 6656/12188 [===============>..............] - ETA: 8s - loss: 6.9121\n",
      " 7168/12188 [================>.............] - ETA: 8s - loss: 6.8961\n",
      " 7680/12188 [=================>............] - ETA: 7s - loss: 6.8644\n",
      " 8192/12188 [===================>..........] - ETA: 6s - loss: 6.8410\n",
      " 8704/12188 [====================>.........] - ETA: 5s - loss: 6.8106\n",
      " 9216/12188 [=====================>........] - ETA: 4s - loss: 6.8146\n",
      " 9728/12188 [======================>.......] - ETA: 4s - loss: 6.7915\n",
      "10240/12188 [========================>.....] - ETA: 3s - loss: 6.7818\n",
      "10752/12188 [=========================>....] - ETA: 2s - loss: 6.7737\n",
      "11264/12188 [==========================>...] - ETA: 1s - loss: 6.7436\n",
      "11776/12188 [===========================>..] - ETA: 1s - loss: 6.7199Epoch 00016: saving model to checkpoints/2017-11-18_1136-seq2seq.hdf5\n",
      "\n",
      "12188/12188 [==============================] - ETA: 0s - loss: 6.7342 - val_loss: 13.8420\n",
      "Epoch 17/50\n",
      "\n",
      "  512/12188 [>.............................] - ETA: 18s - loss: 6.2438\n",
      " 1024/12188 [=>............................] - ETA: 17s - loss: 6.6336\n",
      " 1536/12188 [==>...........................] - ETA: 16s - loss: 6.6066\n",
      " 2048/12188 [====>.........................] - ETA: 15s - loss: 6.5446\n",
      " 2560/12188 [=====>........................] - ETA: 14s - loss: 6.5530\n",
      " 3072/12188 [======>.......................] - ETA: 14s - loss: 6.6754\n",
      " 3584/12188 [=======>......................] - ETA: 13s - loss: 6.7474\n",
      " 4096/12188 [=========>....................] - ETA: 12s - loss: 6.6947\n",
      " 4608/12188 [==========>...................] - ETA: 11s - loss: 6.7087\n",
      " 5120/12188 [===========>..................] - ETA: 11s - loss: 6.6864\n",
      " 5632/12188 [============>.................] - ETA: 10s - loss: 6.6556\n",
      " 6144/12188 [==============>...............] - ETA: 9s - loss: 6.6227 \n",
      " 6656/12188 [===============>..............] - ETA: 8s - loss: 6.6030\n",
      " 7168/12188 [================>.............] - ETA: 8s - loss: 6.6195\n",
      " 7680/12188 [=================>............] - ETA: 7s - loss: 6.5740\n",
      " 8192/12188 [===================>..........] - ETA: 6s - loss: 6.5887\n",
      " 8704/12188 [====================>.........] - ETA: 5s - loss: 6.5460\n",
      " 9216/12188 [=====================>........] - ETA: 4s - loss: 6.5449\n",
      " 9728/12188 [======================>.......] - ETA: 4s - loss: 6.5227\n",
      "10240/12188 [========================>.....] - ETA: 3s - loss: 6.5003\n",
      "10752/12188 [=========================>....] - ETA: 2s - loss: 6.4910\n",
      "11264/12188 [==========================>...] - ETA: 1s - loss: 6.4575\n",
      "11776/12188 [===========================>..] - ETA: 1s - loss: 6.4404Epoch 00017: saving model to checkpoints/2017-11-18_1136-seq2seq.hdf5\n",
      "\n",
      "12188/12188 [==============================] - ETA: 0s - loss: 6.4248 - val_loss: 13.2086\n",
      "Epoch 18/50\n",
      "\n",
      "  512/12188 [>.............................] - ETA: 17s - loss: 6.0248\n",
      " 1024/12188 [=>............................] - ETA: 17s - loss: 6.1034\n",
      " 1536/12188 [==>...........................] - ETA: 16s - loss: 5.9935\n",
      " 2048/12188 [====>.........................] - ETA: 15s - loss: 5.9073\n",
      " 2560/12188 [=====>........................] - ETA: 14s - loss: 6.1172\n",
      " 3072/12188 [======>.......................] - ETA: 14s - loss: 6.1034\n",
      " 3584/12188 [=======>......................] - ETA: 13s - loss: 6.1736\n",
      " 4096/12188 [=========>....................] - ETA: 12s - loss: 6.1708\n",
      " 4608/12188 [==========>...................] - ETA: 11s - loss: 6.1333\n",
      " 5120/12188 [===========>..................] - ETA: 11s - loss: 6.1040\n",
      " 5632/12188 [============>.................] - ETA: 10s - loss: 6.0985\n",
      " 6144/12188 [==============>...............] - ETA: 9s - loss: 6.1106 \n",
      " 6656/12188 [===============>..............] - ETA: 8s - loss: 6.1107\n",
      " 7168/12188 [================>.............] - ETA: 8s - loss: 6.0561\n",
      " 7680/12188 [=================>............] - ETA: 7s - loss: 6.0622\n",
      " 8192/12188 [===================>..........] - ETA: 6s - loss: 6.0576\n",
      " 8704/12188 [====================>.........] - ETA: 5s - loss: 6.0507\n",
      " 9216/12188 [=====================>........] - ETA: 4s - loss: 6.0692\n",
      " 9728/12188 [======================>.......] - ETA: 4s - loss: 6.0583\n",
      "10240/12188 [========================>.....] - ETA: 3s - loss: 6.0939\n",
      "10752/12188 [=========================>....] - ETA: 2s - loss: 6.0789\n",
      "11264/12188 [==========================>...] - ETA: 1s - loss: 6.1123\n",
      "11776/12188 [===========================>..] - ETA: 1s - loss: 6.1027Epoch 00018: saving model to checkpoints/2017-11-18_1136-seq2seq.hdf5\n",
      "\n",
      "12188/12188 [==============================] - ETA: 0s - loss: 6.1141 - val_loss: 12.5968\n",
      "Epoch 19/50\n",
      "\n",
      "  512/12188 [>.............................] - ETA: 18s - loss: 6.0235\n",
      " 1024/12188 [=>............................] - ETA: 17s - loss: 6.0200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1536/12188 [==>...........................] - ETA: 16s - loss: 5.8864\n",
      " 2048/12188 [====>.........................] - ETA: 15s - loss: 5.8197\n",
      " 2560/12188 [=====>........................] - ETA: 15s - loss: 5.9954\n",
      " 3072/12188 [======>.......................] - ETA: 14s - loss: 5.9547\n",
      " 3584/12188 [=======>......................] - ETA: 13s - loss: 5.9238\n",
      " 4096/12188 [=========>....................] - ETA: 12s - loss: 5.9393\n",
      " 4608/12188 [==========>...................] - ETA: 11s - loss: 5.9229\n",
      " 5120/12188 [===========>..................] - ETA: 11s - loss: 5.9076\n",
      " 5632/12188 [============>.................] - ETA: 10s - loss: 5.8987\n",
      " 6144/12188 [==============>...............] - ETA: 9s - loss: 5.9112 \n",
      " 6656/12188 [===============>..............] - ETA: 8s - loss: 5.9143\n",
      " 7168/12188 [================>.............] - ETA: 8s - loss: 5.9338\n",
      " 7680/12188 [=================>............] - ETA: 7s - loss: 5.8968\n",
      " 8192/12188 [===================>..........] - ETA: 6s - loss: 5.8582\n",
      " 8704/12188 [====================>.........] - ETA: 5s - loss: 5.8345\n",
      " 9216/12188 [=====================>........] - ETA: 4s - loss: 5.8201\n",
      " 9728/12188 [======================>.......] - ETA: 4s - loss: 5.8226\n",
      "10240/12188 [========================>.....] - ETA: 3s - loss: 5.8430\n",
      "10752/12188 [=========================>....] - ETA: 2s - loss: 5.8288\n",
      "11264/12188 [==========================>...] - ETA: 1s - loss: 5.8145\n",
      "11776/12188 [===========================>..] - ETA: 1s - loss: 5.8241Epoch 00019: saving model to checkpoints/2017-11-18_1136-seq2seq.hdf5\n",
      "\n",
      "12188/12188 [==============================] - ETA: 0s - loss: 5.8287 - val_loss: 12.0862\n",
      "Epoch 20/50\n",
      "\n",
      "  512/12188 [>.............................] - ETA: 18s - loss: 5.6702\n",
      " 1024/12188 [=>............................] - ETA: 17s - loss: 5.5477\n",
      " 1536/12188 [==>...........................] - ETA: 16s - loss: 5.6590\n",
      " 2048/12188 [====>.........................] - ETA: 15s - loss: 5.7146\n",
      " 2560/12188 [=====>........................] - ETA: 15s - loss: 5.6666\n",
      " 3072/12188 [======>.......................] - ETA: 14s - loss: 5.6603\n",
      " 3584/12188 [=======>......................] - ETA: 13s - loss: 5.6583\n",
      " 4096/12188 [=========>....................] - ETA: 12s - loss: 5.6633\n",
      " 4608/12188 [==========>...................] - ETA: 11s - loss: 5.7427\n",
      " 5120/12188 [===========>..................] - ETA: 11s - loss: 5.7198\n",
      " 5632/12188 [============>.................] - ETA: 10s - loss: 5.6492\n",
      " 6144/12188 [==============>...............] - ETA: 9s - loss: 5.6657 \n",
      " 6656/12188 [===============>..............] - ETA: 8s - loss: 5.6532\n",
      " 7168/12188 [================>.............] - ETA: 8s - loss: 5.6628\n",
      " 7680/12188 [=================>............] - ETA: 7s - loss: 5.6367\n",
      " 8192/12188 [===================>..........] - ETA: 6s - loss: 5.6135\n",
      " 8704/12188 [====================>.........] - ETA: 5s - loss: 5.5930\n",
      " 9216/12188 [=====================>........] - ETA: 4s - loss: 5.5951\n",
      " 9728/12188 [======================>.......] - ETA: 4s - loss: 5.5891\n",
      "10240/12188 [========================>.....] - ETA: 3s - loss: 5.5847\n",
      "10752/12188 [=========================>....] - ETA: 2s - loss: 5.5891\n",
      "11264/12188 [==========================>...] - ETA: 1s - loss: 5.5809\n",
      "11776/12188 [===========================>..] - ETA: 1s - loss: 5.5850Epoch 00020: saving model to checkpoints/2017-11-18_1136-seq2seq.hdf5\n",
      "\n",
      "12188/12188 [==============================] - ETA: 0s - loss: 5.5932 - val_loss: 11.5003\n",
      "Epoch 21/50\n",
      "\n",
      "  512/12188 [>.............................] - ETA: 18s - loss: 5.3167\n",
      " 1024/12188 [=>............................] - ETA: 17s - loss: 5.2575\n",
      " 1536/12188 [==>...........................] - ETA: 16s - loss: 5.4094\n",
      " 2048/12188 [====>.........................] - ETA: 15s - loss: 5.4840\n",
      " 2560/12188 [=====>........................] - ETA: 14s - loss: 5.4717\n",
      " 3072/12188 [======>.......................] - ETA: 14s - loss: 5.4339\n",
      " 3584/12188 [=======>......................] - ETA: 13s - loss: 5.4011\n",
      " 4096/12188 [=========>....................] - ETA: 12s - loss: 5.3514\n",
      " 4608/12188 [==========>...................] - ETA: 11s - loss: 5.3634\n",
      " 5120/12188 [===========>..................] - ETA: 11s - loss: 5.3177\n",
      " 5632/12188 [============>.................] - ETA: 10s - loss: 5.3275\n",
      " 6144/12188 [==============>...............] - ETA: 9s - loss: 5.3561 \n",
      " 6656/12188 [===============>..............] - ETA: 8s - loss: 5.3558\n",
      " 7168/12188 [================>.............] - ETA: 8s - loss: 5.3636\n",
      " 7680/12188 [=================>............] - ETA: 7s - loss: 5.3389\n",
      " 8192/12188 [===================>..........] - ETA: 6s - loss: 5.3373\n",
      " 8704/12188 [====================>.........] - ETA: 5s - loss: 5.3318\n",
      " 9216/12188 [=====================>........] - ETA: 4s - loss: 5.3577\n",
      " 9728/12188 [======================>.......] - ETA: 4s - loss: 5.3649\n",
      "10240/12188 [========================>.....] - ETA: 3s - loss: 5.3395\n",
      "10752/12188 [=========================>....] - ETA: 2s - loss: 5.3263\n",
      "11264/12188 [==========================>...] - ETA: 1s - loss: 5.3421\n",
      "11776/12188 [===========================>..] - ETA: 1s - loss: 5.3370Epoch 00021: saving model to checkpoints/2017-11-18_1136-seq2seq.hdf5\n",
      "\n",
      "12188/12188 [==============================] - ETA: 0s - loss: 5.3265 - val_loss: 10.9933\n",
      "Epoch 22/50\n",
      "\n",
      "  512/12188 [>.............................] - ETA: 18s - loss: 4.9283\n",
      " 1024/12188 [=>............................] - ETA: 17s - loss: 5.0818\n",
      " 1536/12188 [==>...........................] - ETA: 16s - loss: 5.2727\n",
      " 2048/12188 [====>.........................] - ETA: 15s - loss: 5.5442\n",
      " 2560/12188 [=====>........................] - ETA: 15s - loss: 5.5035\n",
      " 3072/12188 [======>.......................] - ETA: 14s - loss: 5.4056\n",
      " 3584/12188 [=======>......................] - ETA: 13s - loss: 5.3132\n",
      " 4096/12188 [=========>....................] - ETA: 12s - loss: 5.2882\n",
      " 4608/12188 [==========>...................] - ETA: 11s - loss: 5.2823\n",
      " 5120/12188 [===========>..................] - ETA: 11s - loss: 5.2386\n",
      " 5632/12188 [============>.................] - ETA: 10s - loss: 5.2468\n",
      " 6144/12188 [==============>...............] - ETA: 9s - loss: 5.2730 \n",
      " 6656/12188 [===============>..............] - ETA: 8s - loss: 5.2514\n",
      " 7168/12188 [================>.............] - ETA: 8s - loss: 5.2939\n",
      " 7680/12188 [=================>............] - ETA: 7s - loss: 5.2892\n",
      " 8192/12188 [===================>..........] - ETA: 6s - loss: 5.2614\n",
      " 8704/12188 [====================>.........] - ETA: 5s - loss: 5.2303\n",
      " 9216/12188 [=====================>........] - ETA: 4s - loss: 5.2180\n",
      " 9728/12188 [======================>.......] - ETA: 4s - loss: 5.2248\n",
      "10240/12188 [========================>.....] - ETA: 3s - loss: 5.2231\n",
      "10752/12188 [=========================>....] - ETA: 2s - loss: 5.2100\n",
      "11264/12188 [==========================>...] - ETA: 1s - loss: 5.2137\n",
      "11776/12188 [===========================>..] - ETA: 1s - loss: 5.2081Epoch 00022: saving model to checkpoints/2017-11-18_1136-seq2seq.hdf5\n",
      "\n",
      "12188/12188 [==============================] - ETA: 0s - loss: 5.1947 - val_loss: 10.5884\n",
      "Epoch 23/50\n",
      "\n",
      "  512/12188 [>.............................] - ETA: 18s - loss: 4.7185\n",
      " 1024/12188 [=>............................] - ETA: 17s - loss: 4.8544\n",
      " 1536/12188 [==>...........................] - ETA: 16s - loss: 4.9274\n",
      " 2048/12188 [====>.........................] - ETA: 15s - loss: 4.8994\n",
      " 2560/12188 [=====>........................] - ETA: 14s - loss: 4.9120\n",
      " 3072/12188 [======>.......................] - ETA: 14s - loss: 4.9188\n",
      " 3584/12188 [=======>......................] - ETA: 13s - loss: 4.8989\n",
      " 4096/12188 [=========>....................] - ETA: 12s - loss: 4.9164\n",
      " 4608/12188 [==========>...................] - ETA: 11s - loss: 4.8855\n",
      " 5120/12188 [===========>..................] - ETA: 11s - loss: 4.8794\n",
      " 5632/12188 [============>.................] - ETA: 10s - loss: 4.8390\n",
      " 6144/12188 [==============>...............] - ETA: 9s - loss: 4.8491 \n",
      " 6656/12188 [===============>..............] - ETA: 8s - loss: 4.8791\n",
      " 7168/12188 [================>.............] - ETA: 8s - loss: 4.8994\n",
      " 7680/12188 [=================>............] - ETA: 7s - loss: 4.9229\n",
      " 8192/12188 [===================>..........] - ETA: 6s - loss: 4.9214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 8704/12188 [====================>.........] - ETA: 5s - loss: 4.9200\n",
      " 9216/12188 [=====================>........] - ETA: 4s - loss: 4.9264\n",
      " 9728/12188 [======================>.......] - ETA: 4s - loss: 4.9419\n",
      "10240/12188 [========================>.....] - ETA: 3s - loss: 4.9466\n",
      "10752/12188 [=========================>....] - ETA: 2s - loss: 4.9461\n",
      "11264/12188 [==========================>...] - ETA: 1s - loss: 4.9456\n",
      "11776/12188 [===========================>..] - ETA: 1s - loss: 4.9505Epoch 00023: saving model to checkpoints/2017-11-18_1136-seq2seq.hdf5\n",
      "\n",
      "12188/12188 [==============================] - ETA: 0s - loss: 4.9367 - val_loss: 10.0716\n",
      "Epoch 24/50\n",
      "\n",
      "  512/12188 [>.............................] - ETA: 17s - loss: 4.5635\n",
      " 1024/12188 [=>............................] - ETA: 17s - loss: 4.6967\n",
      " 1536/12188 [==>...........................] - ETA: 16s - loss: 4.7384\n",
      " 2048/12188 [====>.........................] - ETA: 15s - loss: 4.6816\n",
      " 2560/12188 [=====>........................] - ETA: 14s - loss: 4.7139\n",
      " 3072/12188 [======>.......................] - ETA: 14s - loss: 4.6898\n",
      " 3584/12188 [=======>......................] - ETA: 13s - loss: 4.7418\n",
      " 4096/12188 [=========>....................] - ETA: 12s - loss: 4.7159\n",
      " 4608/12188 [==========>...................] - ETA: 11s - loss: 4.7592\n",
      " 5120/12188 [===========>..................] - ETA: 11s - loss: 4.7641\n",
      " 5632/12188 [============>.................] - ETA: 10s - loss: 4.7509\n",
      " 6144/12188 [==============>...............] - ETA: 9s - loss: 4.7406 \n",
      " 6656/12188 [===============>..............] - ETA: 8s - loss: 4.7302\n",
      " 7168/12188 [================>.............] - ETA: 8s - loss: 4.7626\n",
      " 7680/12188 [=================>............] - ETA: 7s - loss: 4.7609\n",
      " 8192/12188 [===================>..........] - ETA: 6s - loss: 4.7599\n",
      " 8704/12188 [====================>.........] - ETA: 5s - loss: 4.7585\n",
      " 9216/12188 [=====================>........] - ETA: 4s - loss: 4.7472\n",
      " 9728/12188 [======================>.......] - ETA: 4s - loss: 4.7479\n",
      "10240/12188 [========================>.....] - ETA: 3s - loss: 4.7474\n",
      "10752/12188 [=========================>....] - ETA: 2s - loss: 4.7439\n",
      "11264/12188 [==========================>...] - ETA: 1s - loss: 4.7456\n",
      "11776/12188 [===========================>..] - ETA: 1s - loss: 4.7661"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train,\n",
    "          batch_size=bs,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.05,\n",
    "          callbacks=[history,checkpointer,csv_logger,early_stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-18T10:32:08.713366Z",
     "start_time": "2017-11-18T10:32:08.708839Z"
    }
   },
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-18T10:32:08.707276Z",
     "start_time": "2017-11-18T10:32:08.705151Z"
    }
   },
   "source": [
    "## Validation by feeding truth values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-11-18T11:36:28.717Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_preds(y_truth, y_pred):\n",
    "    for junction in range(4):\n",
    "        plt.figure\n",
    "        plt.plot(y_truth[:,junction], color = 'green', label = 'Real traffic')\n",
    "        plt.plot(y_pred[:,junction], color = 'red', label = 'Predicted traffic')\n",
    "        plt.title('Traffic Forecasting at junction %i' % (junction+1))\n",
    "        plt.xlabel('Number of hours from Start')\n",
    "        plt.ylabel('Traffic')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-11-18T11:36:28.724Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-11-18T11:36:28.730Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_preds(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-11-18T11:36:28.736Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return sqrt(mean_squared_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-11-18T11:36:28.743Z"
    }
   },
   "outputs": [],
   "source": [
    "rmse(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation by feeding predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-11-18T11:36:28.752Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pred_seq(model, to_pred, w_size, num_preds=None):\n",
    "    if num_preds == None:\n",
    "        num_preds = to_pred.shape[0]\n",
    "    current = to_pred[0]\n",
    "    predicted = []\n",
    "    for i in range(num_preds):\n",
    "        predicted.append(np.round(model.predict(current[np.newaxis,:,:])[0,:]))\n",
    "        current = current[1:]\n",
    "        current = np.insert(current, [w_size-1], predicted[-1], axis=0)\n",
    "    return np.asarray(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-11-18T11:36:28.762Z"
    }
   },
   "outputs": [],
   "source": [
    "seqpreds = pred_seq(model, X_test, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-11-18T11:36:28.769Z"
    }
   },
   "outputs": [],
   "source": [
    "seqpreds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-11-18T11:36:28.772Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_preds(y_test, seqpreds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-11-18T11:36:28.774Z"
    }
   },
   "outputs": [],
   "source": [
    "rmse(y_test, seqpreds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
